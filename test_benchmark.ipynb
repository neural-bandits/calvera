{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network input size: 256, output size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exploration_rate': 0.1, 'lr': '1e-4', 'weight_decay': 1e-05, 'min_samples_required_for_training': 16, 'initial_train_steps': 16, 'n_embedding_size': 128, 'contextualization_after_network': True, 'n_arms': 2, 'selector': <calvera.utils.selectors.ArgMaxSelector object at 0x30db84940>, 'n_features': 256, 'train_batch_size': 32, 'network': BertWrapper(\n",
      "  (network): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 128)\n",
      "      (token_type_embeddings): Embedding(2, 128)\n",
      "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-1): 2 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "), 'buffer': <calvera.utils.data_storage.ListDataBuffer object at 0x30db85b10>}\n",
      "Bandit moved to device: cpu\n",
      "Running benchmark for neural_linear on imdb dataset.\n",
      "Config: {'dataset': 'imdb', 'bandit': 'neural_linear', 'max_samples': 1000, 'selector': 'argmax', 'feedback_delay': 1, 'forward_batch_size': 1, 'max_steps': 1024, 'train_batch_size': 32, 'gradient_clip_val': 20.0, 'network': 'bert', 'data_strategy': 'all', 'bandit_hparams': {'exploration_rate': 0.1, 'lr': '1e-4', 'weight_decay': 1e-05, 'min_samples_required_for_training': 16, 'initial_train_steps': 16, 'n_embedding_size': 128, 'contextualization_after_network': True, 'n_arms': 2, 'selector': <calvera.utils.selectors.ArgMaxSelector object at 0x30db84940>, 'n_features': 256, 'train_batch_size': 32, 'network': BertWrapper(\n",
      "  (network): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 128)\n",
      "      (token_type_embeddings): Embedding(2, 128)\n",
      "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-1): 2 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "), 'buffer': <calvera.utils.data_storage.ListDataBuffer object at 0x30db85b10>}, 'seed': 42, 'data_sampler': None}\n",
      "Dataset imdb: \n",
      "24904 samples with 256 features and 2 actions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s, acc_regret=0, avg_regret=0, avg_reward=1, regret=0, reward=1]/Users/robert/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/robert/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  0%|          | 1/1000 [00:00<05:04,  3.29it/s, acc_regret=1, avg_regret=0.5, avg_reward=0.5, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  0%|          | 2/1000 [00:00<03:41,  4.50it/s, acc_regret=2, avg_regret=0.667, avg_reward=0.333, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  0%|          | 3/1000 [00:00<03:10,  5.23it/s, acc_regret=2, avg_regret=0.5, avg_reward=0.5, regret=0, reward=1]    Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  0%|          | 4/1000 [00:00<03:00,  5.53it/s, acc_regret=3, avg_regret=0.6, avg_reward=0.4, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  0%|          | 5/1000 [00:00<02:58,  5.58it/s, acc_regret=3, avg_regret=0.5, avg_reward=0.5, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|          | 6/1000 [00:01<03:10,  5.23it/s, acc_regret=3, avg_regret=0.429, avg_reward=0.571, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|          | 7/1000 [00:01<03:17,  5.03it/s, acc_regret=3, avg_regret=0.375, avg_reward=0.625, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|          | 8/1000 [00:01<03:34,  4.62it/s, acc_regret=3, avg_regret=0.333, avg_reward=0.667, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|          | 9/1000 [00:01<03:30,  4.71it/s, acc_regret=4, avg_regret=0.4, avg_reward=0.6, regret=1, reward=0]    Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|          | 10/1000 [00:02<03:29,  4.72it/s, acc_regret=5, avg_regret=0.455, avg_reward=0.545, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|          | 11/1000 [00:02<03:31,  4.67it/s, acc_regret=5, avg_regret=0.417, avg_reward=0.583, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|          | 12/1000 [00:02<03:29,  4.71it/s, acc_regret=5, avg_regret=0.385, avg_reward=0.615, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|▏         | 13/1000 [00:02<03:31,  4.66it/s, acc_regret=6, avg_regret=0.429, avg_reward=0.571, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|▏         | 14/1000 [00:02<03:27,  4.76it/s, acc_regret=7, avg_regret=0.467, avg_reward=0.533, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 15/1000 [00:03<03:39,  4.49it/s, acc_regret=7, avg_regret=0.438, avg_reward=0.562, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 16/1000 [00:03<03:34,  4.59it/s, acc_regret=8, avg_regret=0.471, avg_reward=0.529, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 16/1000 [00:03<03:34,  4.59it/s, acc_regret=9, avg_regret=0.5, avg_reward=0.5, regret=1, reward=0]    Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 18/1000 [00:03<02:21,  6.93it/s, acc_regret=10, avg_regret=0.526, avg_reward=0.474, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 18/1000 [00:03<02:21,  6.93it/s, acc_regret=11, avg_regret=0.55, avg_reward=0.45, regret=1, reward=0]  Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 20/1000 [00:03<01:46,  9.17it/s, acc_regret=12, avg_regret=0.571, avg_reward=0.429, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 20/1000 [00:03<01:46,  9.17it/s, acc_regret=13, avg_regret=0.591, avg_reward=0.409, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 22/1000 [00:03<01:31, 10.71it/s, acc_regret=14, avg_regret=0.609, avg_reward=0.391, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 22/1000 [00:03<01:31, 10.71it/s, acc_regret=14, avg_regret=0.583, avg_reward=0.417, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 24/1000 [00:03<01:20, 12.20it/s, acc_regret=14, avg_regret=0.56, avg_reward=0.44, regret=0, reward=1]  Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 24/1000 [00:03<01:20, 12.20it/s, acc_regret=15, avg_regret=0.577, avg_reward=0.423, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 26/1000 [00:03<01:11, 13.59it/s, acc_regret=16, avg_regret=0.593, avg_reward=0.407, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 26/1000 [00:04<01:11, 13.59it/s, acc_regret=16, avg_regret=0.571, avg_reward=0.429, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 28/1000 [00:04<01:06, 14.61it/s, acc_regret=16, avg_regret=0.552, avg_reward=0.448, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 28/1000 [00:04<01:06, 14.61it/s, acc_regret=17, avg_regret=0.567, avg_reward=0.433, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 30/1000 [00:04<01:02, 15.42it/s, acc_regret=17, avg_regret=0.548, avg_reward=0.452, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 30/1000 [00:04<01:02, 15.42it/s, acc_regret=18, avg_regret=0.562, avg_reward=0.438, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 32/1000 [00:04<02:34,  6.28it/s, acc_regret=18, avg_regret=0.545, avg_reward=0.455, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 32/1000 [00:04<02:34,  6.28it/s, acc_regret=19, avg_regret=0.559, avg_reward=0.441, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 34/1000 [00:05<02:03,  7.84it/s, acc_regret=19, avg_regret=0.543, avg_reward=0.457, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 34/1000 [00:05<02:03,  7.84it/s, acc_regret=20, avg_regret=0.556, avg_reward=0.444, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▎         | 36/1000 [00:05<01:48,  8.92it/s, acc_regret=21, avg_regret=0.568, avg_reward=0.432, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▎         | 36/1000 [00:05<01:48,  8.92it/s, acc_regret=22, avg_regret=0.579, avg_reward=0.421, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 38/1000 [00:05<01:32, 10.37it/s, acc_regret=22, avg_regret=0.564, avg_reward=0.436, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 38/1000 [00:05<01:32, 10.37it/s, acc_regret=23, avg_regret=0.575, avg_reward=0.425, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 40/1000 [00:05<01:21, 11.76it/s, acc_regret=24, avg_regret=0.585, avg_reward=0.415, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 40/1000 [00:05<01:21, 11.76it/s, acc_regret=25, avg_regret=0.595, avg_reward=0.405, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 42/1000 [00:05<01:13, 13.04it/s, acc_regret=25, avg_regret=0.581, avg_reward=0.419, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 42/1000 [00:05<01:13, 13.04it/s, acc_regret=26, avg_regret=0.591, avg_reward=0.409, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 44/1000 [00:05<01:07, 14.19it/s, acc_regret=27, avg_regret=0.6, avg_reward=0.4, regret=1, reward=0]    Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 44/1000 [00:05<01:07, 14.19it/s, acc_regret=27, avg_regret=0.587, avg_reward=0.413, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 44/1000 [00:05<01:07, 14.19it/s, acc_regret=27, avg_regret=0.574, avg_reward=0.426, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▍         | 47/1000 [00:05<00:59, 15.98it/s, acc_regret=27, avg_regret=0.562, avg_reward=0.438, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▍         | 47/1000 [00:06<00:59, 15.98it/s, acc_regret=28, avg_regret=0.571, avg_reward=0.429, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▍         | 49/1000 [00:06<02:05,  7.55it/s, acc_regret=28, avg_regret=0.56, avg_reward=0.44, regret=0, reward=1]  Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▍         | 49/1000 [00:06<02:05,  7.55it/s, acc_regret=29, avg_regret=0.569, avg_reward=0.431, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▌         | 51/1000 [00:06<01:45,  8.99it/s, acc_regret=30, avg_regret=0.577, avg_reward=0.423, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▌         | 51/1000 [00:06<01:45,  8.99it/s, acc_regret=31, avg_regret=0.585, avg_reward=0.415, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▌         | 53/1000 [00:06<01:34, 10.02it/s, acc_regret=32, avg_regret=0.593, avg_reward=0.407, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▌         | 53/1000 [00:06<01:34, 10.02it/s, acc_regret=32, avg_regret=0.582, avg_reward=0.418, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 55/1000 [00:06<01:23, 11.26it/s, acc_regret=33, avg_regret=0.589, avg_reward=0.411, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 55/1000 [00:06<01:23, 11.26it/s, acc_regret=34, avg_regret=0.596, avg_reward=0.404, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 57/1000 [00:06<01:16, 12.36it/s, acc_regret=34, avg_regret=0.586, avg_reward=0.414, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 57/1000 [00:07<01:16, 12.36it/s, acc_regret=35, avg_regret=0.593, avg_reward=0.407, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 59/1000 [00:07<01:09, 13.49it/s, acc_regret=36, avg_regret=0.6, avg_reward=0.4, regret=1, reward=0]    Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 59/1000 [00:07<01:09, 13.49it/s, acc_regret=37, avg_regret=0.607, avg_reward=0.393, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 61/1000 [00:07<01:04, 14.46it/s, acc_regret=37, avg_regret=0.597, avg_reward=0.403, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 61/1000 [00:07<01:04, 14.46it/s, acc_regret=37, avg_regret=0.587, avg_reward=0.413, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 61/1000 [00:07<01:04, 14.46it/s, acc_regret=37, avg_regret=0.578, avg_reward=0.422, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▋         | 64/1000 [00:08<03:46,  4.14it/s, acc_regret=38, avg_regret=0.585, avg_reward=0.415, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▋         | 64/1000 [00:08<03:46,  4.14it/s, acc_regret=39, avg_regret=0.591, avg_reward=0.409, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 66/1000 [00:08<03:03,  5.09it/s, acc_regret=40, avg_regret=0.597, avg_reward=0.403, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 66/1000 [00:08<03:03,  5.09it/s, acc_regret=41, avg_regret=0.603, avg_reward=0.397, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 68/1000 [00:08<02:25,  6.41it/s, acc_regret=41, avg_regret=0.594, avg_reward=0.406, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 68/1000 [00:09<02:25,  6.41it/s, acc_regret=41, avg_regret=0.586, avg_reward=0.414, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 70/1000 [00:09<01:59,  7.76it/s, acc_regret=42, avg_regret=0.592, avg_reward=0.408, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 70/1000 [00:09<01:59,  7.76it/s, acc_regret=43, avg_regret=0.597, avg_reward=0.403, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 72/1000 [00:09<01:38,  9.40it/s, acc_regret=43, avg_regret=0.589, avg_reward=0.411, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 72/1000 [00:09<01:38,  9.40it/s, acc_regret=43, avg_regret=0.581, avg_reward=0.419, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 74/1000 [00:09<01:23, 11.05it/s, acc_regret=43, avg_regret=0.573, avg_reward=0.427, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 74/1000 [00:09<01:23, 11.05it/s, acc_regret=44, avg_regret=0.579, avg_reward=0.421, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 76/1000 [00:09<01:14, 12.36it/s, acc_regret=44, avg_regret=0.571, avg_reward=0.429, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 76/1000 [00:09<01:14, 12.36it/s, acc_regret=44, avg_regret=0.564, avg_reward=0.436, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 78/1000 [00:09<01:07, 13.76it/s, acc_regret=44, avg_regret=0.557, avg_reward=0.443, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 78/1000 [00:09<01:07, 13.76it/s, acc_regret=44, avg_regret=0.55, avg_reward=0.45, regret=0, reward=1]  Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 80/1000 [00:10<02:40,  5.73it/s, acc_regret=45, avg_regret=0.556, avg_reward=0.444, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 80/1000 [00:10<02:40,  5.73it/s, acc_regret=45, avg_regret=0.549, avg_reward=0.451, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 82/1000 [00:10<02:08,  7.12it/s, acc_regret=46, avg_regret=0.554, avg_reward=0.446, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 82/1000 [00:10<02:08,  7.12it/s, acc_regret=46, avg_regret=0.548, avg_reward=0.452, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 84/1000 [00:10<01:47,  8.54it/s, acc_regret=47, avg_regret=0.553, avg_reward=0.447, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 84/1000 [00:10<01:47,  8.54it/s, acc_regret=48, avg_regret=0.558, avg_reward=0.442, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▊         | 86/1000 [00:10<01:29, 10.27it/s, acc_regret=48, avg_regret=0.552, avg_reward=0.448, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▊         | 86/1000 [00:11<01:29, 10.27it/s, acc_regret=48, avg_regret=0.545, avg_reward=0.455, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▉         | 88/1000 [00:11<01:50,  8.22it/s, acc_regret=49, avg_regret=0.551, avg_reward=0.449, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▉         | 88/1000 [00:11<01:50,  8.22it/s, acc_regret=50, avg_regret=0.556, avg_reward=0.444, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▉         | 90/1000 [00:11<01:33,  9.69it/s, acc_regret=51, avg_regret=0.56, avg_reward=0.44, regret=1, reward=0]  Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▉         | 90/1000 [00:11<01:33,  9.69it/s, acc_regret=52, avg_regret=0.565, avg_reward=0.435, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▉         | 92/1000 [00:11<01:21, 11.10it/s, acc_regret=52, avg_regret=0.559, avg_reward=0.441, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▉         | 92/1000 [00:11<01:21, 11.10it/s, acc_regret=53, avg_regret=0.564, avg_reward=0.436, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▉         | 94/1000 [00:11<01:12, 12.46it/s, acc_regret=53, avg_regret=0.558, avg_reward=0.442, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▉         | 94/1000 [00:11<01:12, 12.46it/s, acc_regret=54, avg_regret=0.562, avg_reward=0.438, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|▉         | 96/1000 [00:12<02:54,  5.17it/s, acc_regret=55, avg_regret=0.567, avg_reward=0.433, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|▉         | 96/1000 [00:12<02:54,  5.17it/s, acc_regret=56, avg_regret=0.571, avg_reward=0.429, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|▉         | 98/1000 [00:12<02:19,  6.49it/s, acc_regret=56, avg_regret=0.566, avg_reward=0.434, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|▉         | 98/1000 [00:12<02:19,  6.49it/s, acc_regret=56, avg_regret=0.56, avg_reward=0.44, regret=0, reward=1]  Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|█         | 100/1000 [00:12<01:51,  8.10it/s, acc_regret=57, avg_regret=0.564, avg_reward=0.436, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|█         | 100/1000 [00:12<01:51,  8.10it/s, acc_regret=57, avg_regret=0.559, avg_reward=0.441, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|█         | 102/1000 [00:12<01:35,  9.41it/s, acc_regret=57, avg_regret=0.553, avg_reward=0.447, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|█         | 102/1000 [00:12<01:35,  9.41it/s, acc_regret=57, avg_regret=0.548, avg_reward=0.452, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|█         | 104/1000 [00:12<01:37,  9.17it/s, acc_regret=58, avg_regret=0.552, avg_reward=0.448, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|█         | 104/1000 [00:13<01:37,  9.17it/s, acc_regret=59, avg_regret=0.557, avg_reward=0.443, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█         | 106/1000 [00:13<01:42,  8.74it/s, acc_regret=60, avg_regret=0.561, avg_reward=0.439, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█         | 106/1000 [00:13<01:42,  8.74it/s, acc_regret=61, avg_regret=0.565, avg_reward=0.435, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█         | 108/1000 [00:13<02:16,  6.51it/s, acc_regret=61, avg_regret=0.56, avg_reward=0.44, regret=0, reward=1]  Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█         | 109/1000 [00:13<02:08,  6.92it/s, acc_regret=62, avg_regret=0.564, avg_reward=0.436, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█         | 110/1000 [00:13<02:02,  7.29it/s, acc_regret=62, avg_regret=0.559, avg_reward=0.441, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█         | 111/1000 [00:14<02:06,  7.01it/s, acc_regret=63, avg_regret=0.562, avg_reward=0.438, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█         | 112/1000 [00:15<07:22,  2.01it/s, acc_regret=64, avg_regret=0.566, avg_reward=0.434, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█         | 112/1000 [00:15<07:22,  2.01it/s, acc_regret=64, avg_regret=0.561, avg_reward=0.439, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█▏        | 114/1000 [00:15<04:47,  3.08it/s, acc_regret=65, avg_regret=0.565, avg_reward=0.435, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█▏        | 114/1000 [00:15<04:47,  3.08it/s, acc_regret=65, avg_regret=0.56, avg_reward=0.44, regret=0, reward=1]  Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 116/1000 [00:15<03:28,  4.24it/s, acc_regret=66, avg_regret=0.564, avg_reward=0.436, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 116/1000 [00:16<03:28,  4.24it/s, acc_regret=67, avg_regret=0.568, avg_reward=0.432, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 118/1000 [00:16<02:36,  5.63it/s, acc_regret=68, avg_regret=0.571, avg_reward=0.429, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 118/1000 [00:16<02:36,  5.63it/s, acc_regret=69, avg_regret=0.575, avg_reward=0.425, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 120/1000 [00:16<02:19,  6.30it/s, acc_regret=70, avg_regret=0.579, avg_reward=0.421, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 120/1000 [00:16<02:19,  6.30it/s, acc_regret=71, avg_regret=0.582, avg_reward=0.418, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 122/1000 [00:16<01:58,  7.41it/s, acc_regret=72, avg_regret=0.585, avg_reward=0.415, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 122/1000 [00:16<01:58,  7.41it/s, acc_regret=72, avg_regret=0.581, avg_reward=0.419, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 124/1000 [00:16<01:39,  8.85it/s, acc_regret=72, avg_regret=0.576, avg_reward=0.424, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 124/1000 [00:16<01:39,  8.85it/s, acc_regret=73, avg_regret=0.579, avg_reward=0.421, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 126/1000 [00:16<01:28,  9.86it/s, acc_regret=73, avg_regret=0.575, avg_reward=0.425, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 126/1000 [00:16<01:28,  9.86it/s, acc_regret=74, avg_regret=0.578, avg_reward=0.422, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 128/1000 [00:18<05:00,  2.90it/s, acc_regret=74, avg_regret=0.574, avg_reward=0.426, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 129/1000 [00:18<04:22,  3.32it/s, acc_regret=74, avg_regret=0.569, avg_reward=0.431, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 129/1000 [00:18<04:22,  3.32it/s, acc_regret=75, avg_regret=0.573, avg_reward=0.427, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 131/1000 [00:18<03:14,  4.46it/s, acc_regret=75, avg_regret=0.568, avg_reward=0.432, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 131/1000 [00:18<03:14,  4.46it/s, acc_regret=75, avg_regret=0.564, avg_reward=0.436, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 133/1000 [00:19<02:33,  5.65it/s, acc_regret=76, avg_regret=0.567, avg_reward=0.433, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 133/1000 [00:19<02:33,  5.65it/s, acc_regret=76, avg_regret=0.563, avg_reward=0.437, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 14%|█▎        | 135/1000 [00:19<02:03,  7.03it/s, acc_regret=77, avg_regret=0.566, avg_reward=0.434, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 14%|█▎        | 135/1000 [00:19<02:03,  7.03it/s, acc_regret=78, avg_regret=0.569, avg_reward=0.431, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 14%|█▎        | 137/1000 [00:19<02:01,  7.09it/s, acc_regret=79, avg_regret=0.572, avg_reward=0.428, regret=1, reward=0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcalvera\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_from_yaml\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun_from_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexperiments/datasets/imdb_reviews/config.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/calvera/src/calvera/benchmark/benchmark.py:678\u001b[0m, in \u001b[0;36mrun_from_yaml\u001b[0;34m(config_path, save_plots, suppress_plots)\u001b[0m\n\u001b[1;32m    676\u001b[0m     run_comparison(config, log_dir, save_plots, suppress_plots)\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_plots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuppress_plots\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/calvera/src/calvera/benchmark/benchmark.py:525\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(config, log_dir, save_plots, suppress_plots)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(benchmark\u001b[38;5;241m.\u001b[39mdataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbenchmark\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mcontext_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbenchmark\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mnum_actions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m actions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    524\u001b[0m )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mbenchmark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m BenchmarkAnalyzer(log_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_metrics.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_plots, suppress_plots)\n\u001b[1;32m    528\u001b[0m analyzer\u001b[38;5;241m.\u001b[39mload_metrics(logger\u001b[38;5;241m.\u001b[39mlog_dir)\n",
      "File \u001b[0;32m~/Desktop/calvera/src/calvera/benchmark/benchmark.py:443\u001b[0m, in \u001b[0;36mBanditBenchmark.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# Only provide the `chosen_action` if necessary.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m chosen_actions_pass \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    437\u001b[0m     chosen_actions\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontextualization_after_network\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbandit\u001b[38;5;241m.\u001b[39mhparams\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbandit\u001b[38;5;241m.\u001b[39mhparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontextualization_after_network\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    441\u001b[0m )\n\u001b[0;32m--> 443\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbandit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord_feedback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchosen_contextualized_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealized_rewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchosen_actions_pass\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# Train the bandit on the current feedback\u001b[39;00m\n\u001b[1;32m    445\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbandit)\n",
      "File \u001b[0;32m~/Desktop/calvera/src/calvera/bandits/neural_linear_bandit.py:399\u001b[0m, in \u001b[0;36mNeuralLinearBandit.record_feedback\u001b[0;34m(self, contextualized_actions, rewards, chosen_actions)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Record a pair of actions and rewards for the bandit.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m        if there is only a single contextualized action (see `contextualization_after_network`).\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# TODO: embedding actions is unnecessary if we will update the network later anyways. See issue #149.\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m embedded_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_contextualized_actions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontextualized_actions\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape: (batch_size, n_actions, n_embedding_size)\u001b[39;00m\n\u001b[1;32m    403\u001b[0m chosen_actions_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(chosen_actions, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m chosen_actions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    405\u001b[0m     chosen_actions_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m embedded_actions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    406\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf there is only a single action, the chosen_actions_idx must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/calvera/src/calvera/bandits/neural_linear_bandit.py:296\u001b[0m, in \u001b[0;36mNeuralLinearBandit._get_contextualized_actions\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sample\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input data must have shape (batch_size, n_arms, ...).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sample\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf `contextualization_after_network` is True, `n_arms` must be 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBut shape is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m )\n\u001b[1;32m    293\u001b[0m contextualized_embeddings: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontextualizer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mforward(input_data))\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_data, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontextualizer(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    297\u001b[0m )\n\u001b[1;32m    298\u001b[0m \u001b[38;5;66;03m# Shape (batch_size, n_arms, model_output_size * n_arms)\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    300\u001b[0m     contextualized_embeddings\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m    301\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe contextualized embeddings must have shape (batch_size, n_arms, model_output_size * n_arms).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/calvera/src/calvera/utils/network_wrappers.py:28\u001b[0m, in \u001b[0;36mBertWrapper.forward\u001b[0;34m(self, *x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m---> 28\u001b[0m output: BaseModelOutputWithPoolingAndCrossAttentions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#     output: BaseModelOutputWithPoolingAndCrossAttentions = self.network(x.squeeze(1))\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:627\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    624\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    625\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 627\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/transformers/pytorch_utils.py:261\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:639\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 639\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 539\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from calvera.benchmark.benchmark import run_from_yaml\n",
    "\n",
    "run_from_yaml(\"experiments/datasets/imdb_reviews/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network input size: 12288, output size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exploration_rate': 0.1, 'lr': '1e-4', 'weight_decay': 1e-05, 'min_samples_required_for_training': 16, 'initial_train_steps': 16, 'n_embedding_size': 128, 'contextualization_after_network': True, 'n_arms': 10, 'selector': <calvera.utils.selectors.ArgMaxSelector object at 0x175286260>, 'n_features': 12288, 'train_batch_size': 32, 'network': ResNetWrapper(\n",
      "  (network): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (dim_reduction): Linear(in_features=512, out_features=128, bias=True)\n",
      "), 'buffer': <calvera.utils.data_storage.ListDataBuffer object at 0x175285060>}\n",
      "Bandit moved to device: cpu\n",
      "Running benchmark for neural_linear on tiny_imagenet dataset.\n",
      "Config: {'dataset': 'tiny_imagenet', 'bandit': 'neural_linear', 'max_samples': 1000, 'selector': 'argmax', 'feedback_delay': 1, 'forward_batch_size': 1, 'max_steps': 1024, 'train_batch_size': 32, 'gradient_clip_val': 20.0, 'network': 'resnet18', 'data_strategy': 'all', 'bandit_hparams': {'exploration_rate': 0.1, 'lr': '1e-4', 'weight_decay': 1e-05, 'min_samples_required_for_training': 16, 'initial_train_steps': 16, 'n_embedding_size': 128, 'contextualization_after_network': True, 'n_arms': 10, 'selector': <calvera.utils.selectors.ArgMaxSelector object at 0x175286260>, 'n_features': 12288, 'train_batch_size': 32, 'network': ResNetWrapper(\n",
      "  (network): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (dim_reduction): Linear(in_features=512, out_features=128, bias=True)\n",
      "), 'buffer': <calvera.utils.data_storage.ListDataBuffer object at 0x175285060>}, 'seed': 42, 'data_sampler': None}\n",
      "Dataset tiny_imagenet: \n",
      "5000 samples with 12288 features and 10 actions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s, acc_regret=1, avg_regret=1, avg_reward=0, regret=1, reward=0]/Users/robert/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/robert/miniconda3/envs/neural_bandits/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  0%|          | 1/1000 [00:00<07:20,  2.27it/s, acc_regret=2, avg_regret=1, avg_reward=0, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  0%|          | 2/1000 [00:00<07:36,  2.19it/s, acc_regret=3, avg_regret=1, avg_reward=0, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  0%|          | 3/1000 [00:01<07:29,  2.22it/s, acc_regret=4, avg_regret=1, avg_reward=0, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  0%|          | 4/1000 [00:01<07:28,  2.22it/s, acc_regret=5, avg_regret=1, avg_reward=0, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  0%|          | 5/1000 [00:02<07:41,  2.16it/s, acc_regret=6, avg_regret=1, avg_reward=0, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|          | 6/1000 [00:02<07:58,  2.08it/s, acc_regret=7, avg_regret=1, avg_reward=0, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|          | 7/1000 [00:03<08:30,  1.94it/s, acc_regret=7, avg_regret=0.875, avg_reward=0.125, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|          | 8/1000 [00:04<08:59,  1.84it/s, acc_regret=8, avg_regret=0.889, avg_reward=0.111, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|          | 9/1000 [00:04<09:24,  1.76it/s, acc_regret=9, avg_regret=0.9, avg_reward=0.1, regret=1, reward=0]    Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|          | 10/1000 [00:05<09:46,  1.69it/s, acc_regret=10, avg_regret=0.909, avg_reward=0.0909, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|          | 11/1000 [00:06<10:19,  1.60it/s, acc_regret=11, avg_regret=0.917, avg_reward=0.0833, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|          | 12/1000 [00:06<10:40,  1.54it/s, acc_regret=12, avg_regret=0.923, avg_reward=0.0769, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|▏         | 13/1000 [00:07<11:31,  1.43it/s, acc_regret=13, avg_regret=0.929, avg_reward=0.0714, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  1%|▏         | 14/1000 [00:08<12:06,  1.36it/s, acc_regret=14, avg_regret=0.933, avg_reward=0.0667, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 15/1000 [00:09<12:54,  1.27it/s, acc_regret=15, avg_regret=0.938, avg_reward=0.0625, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 16/1000 [00:11<18:28,  1.13s/it, acc_regret=16, avg_regret=0.941, avg_reward=0.0588, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 17/1000 [00:11<13:32,  1.21it/s, acc_regret=17, avg_regret=0.944, avg_reward=0.0556, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 18/1000 [00:11<10:05,  1.62it/s, acc_regret=18, avg_regret=0.947, avg_reward=0.0526, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 19/1000 [00:11<07:41,  2.13it/s, acc_regret=19, avg_regret=0.95, avg_reward=0.05, regret=1, reward=0]   Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 20/1000 [00:11<06:09,  2.65it/s, acc_regret=20, avg_regret=0.952, avg_reward=0.0476, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 21/1000 [00:11<05:08,  3.17it/s, acc_regret=21, avg_regret=0.955, avg_reward=0.0455, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 22/1000 [00:12<04:17,  3.81it/s, acc_regret=21, avg_regret=0.913, avg_reward=0.087, regret=0, reward=1] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 23/1000 [00:12<03:40,  4.42it/s, acc_regret=22, avg_regret=0.917, avg_reward=0.0833, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▏         | 24/1000 [00:12<03:15,  5.00it/s, acc_regret=23, avg_regret=0.92, avg_reward=0.08, regret=1, reward=0]   Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  2%|▎         | 25/1000 [00:12<02:56,  5.51it/s, acc_regret=24, avg_regret=0.923, avg_reward=0.0769, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 26/1000 [00:12<02:47,  5.81it/s, acc_regret=25, avg_regret=0.926, avg_reward=0.0741, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 27/1000 [00:12<03:32,  4.58it/s, acc_regret=26, avg_regret=0.929, avg_reward=0.0714, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 28/1000 [00:13<03:06,  5.20it/s, acc_regret=27, avg_regret=0.931, avg_reward=0.069, regret=1, reward=0] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 29/1000 [00:13<02:57,  5.49it/s, acc_regret=28, avg_regret=0.933, avg_reward=0.0667, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 30/1000 [00:13<02:45,  5.86it/s, acc_regret=29, avg_regret=0.935, avg_reward=0.0645, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 31/1000 [00:13<02:38,  6.11it/s, acc_regret=30, avg_regret=0.938, avg_reward=0.0625, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 32/1000 [00:16<17:48,  1.10s/it, acc_regret=31, avg_regret=0.939, avg_reward=0.0606, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 33/1000 [00:16<13:07,  1.23it/s, acc_regret=32, avg_regret=0.941, avg_reward=0.0588, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  3%|▎         | 34/1000 [00:17<09:51,  1.63it/s, acc_regret=33, avg_regret=0.943, avg_reward=0.0571, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▎         | 35/1000 [00:17<07:33,  2.13it/s, acc_regret=34, avg_regret=0.944, avg_reward=0.0556, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▎         | 36/1000 [00:17<05:54,  2.72it/s, acc_regret=35, avg_regret=0.946, avg_reward=0.0541, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▎         | 37/1000 [00:17<04:49,  3.32it/s, acc_regret=35, avg_regret=0.921, avg_reward=0.0789, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 38/1000 [00:17<04:00,  3.99it/s, acc_regret=36, avg_regret=0.923, avg_reward=0.0769, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 39/1000 [00:17<03:26,  4.66it/s, acc_regret=37, avg_regret=0.925, avg_reward=0.075, regret=1, reward=0] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 40/1000 [00:17<03:01,  5.29it/s, acc_regret=38, avg_regret=0.927, avg_reward=0.0732, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 41/1000 [00:18<02:44,  5.82it/s, acc_regret=39, avg_regret=0.929, avg_reward=0.0714, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 42/1000 [00:18<02:32,  6.28it/s, acc_regret=40, avg_regret=0.93, avg_reward=0.0698, regret=1, reward=0] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 43/1000 [00:18<02:28,  6.44it/s, acc_regret=41, avg_regret=0.932, avg_reward=0.0682, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 44/1000 [00:18<02:22,  6.73it/s, acc_regret=42, avg_regret=0.933, avg_reward=0.0667, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  4%|▍         | 45/1000 [00:18<02:15,  7.05it/s, acc_regret=43, avg_regret=0.935, avg_reward=0.0652, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▍         | 46/1000 [00:18<02:10,  7.30it/s, acc_regret=44, avg_regret=0.936, avg_reward=0.0638, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▍         | 47/1000 [00:18<02:13,  7.15it/s, acc_regret=45, avg_regret=0.938, avg_reward=0.0625, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▍         | 48/1000 [00:24<27:05,  1.71s/it, acc_regret=46, avg_regret=0.939, avg_reward=0.0612, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▍         | 49/1000 [00:24<19:39,  1.24s/it, acc_regret=47, avg_regret=0.94, avg_reward=0.06, regret=1, reward=0]   Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▌         | 50/1000 [00:24<14:24,  1.10it/s, acc_regret=48, avg_regret=0.941, avg_reward=0.0588, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▌         | 51/1000 [00:24<10:42,  1.48it/s, acc_regret=49, avg_regret=0.942, avg_reward=0.0577, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▌         | 52/1000 [00:24<08:07,  1.94it/s, acc_regret=50, avg_regret=0.943, avg_reward=0.0566, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▌         | 53/1000 [00:24<06:17,  2.51it/s, acc_regret=50, avg_regret=0.926, avg_reward=0.0741, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  5%|▌         | 54/1000 [00:25<05:00,  3.15it/s, acc_regret=51, avg_regret=0.927, avg_reward=0.0727, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 55/1000 [00:25<05:08,  3.06it/s, acc_regret=52, avg_regret=0.929, avg_reward=0.0714, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 56/1000 [00:25<04:16,  3.69it/s, acc_regret=53, avg_regret=0.93, avg_reward=0.0702, regret=1, reward=0] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 57/1000 [00:25<03:40,  4.27it/s, acc_regret=54, avg_regret=0.931, avg_reward=0.069, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 58/1000 [00:26<03:16,  4.80it/s, acc_regret=55, avg_regret=0.932, avg_reward=0.0678, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 59/1000 [00:26<03:53,  4.02it/s, acc_regret=56, avg_regret=0.933, avg_reward=0.0667, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 60/1000 [00:26<03:22,  4.65it/s, acc_regret=57, avg_regret=0.934, avg_reward=0.0656, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 61/1000 [00:26<02:58,  5.26it/s, acc_regret=58, avg_regret=0.935, avg_reward=0.0645, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▌         | 62/1000 [00:26<02:42,  5.79it/s, acc_regret=59, avg_regret=0.937, avg_reward=0.0635, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▋         | 63/1000 [00:26<02:30,  6.25it/s, acc_regret=60, avg_regret=0.938, avg_reward=0.0625, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▋         | 64/1000 [00:32<31:16,  2.00s/it, acc_regret=61, avg_regret=0.938, avg_reward=0.0615, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  6%|▋         | 65/1000 [00:33<22:33,  1.45s/it, acc_regret=62, avg_regret=0.939, avg_reward=0.0606, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 66/1000 [00:33<16:26,  1.06s/it, acc_regret=63, avg_regret=0.94, avg_reward=0.0597, regret=1, reward=0] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 67/1000 [00:33<12:07,  1.28it/s, acc_regret=64, avg_regret=0.941, avg_reward=0.0588, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 68/1000 [00:33<09:04,  1.71it/s, acc_regret=64, avg_regret=0.928, avg_reward=0.0725, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 69/1000 [00:33<06:58,  2.22it/s, acc_regret=65, avg_regret=0.929, avg_reward=0.0714, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 70/1000 [00:33<05:28,  2.83it/s, acc_regret=66, avg_regret=0.93, avg_reward=0.0704, regret=1, reward=0] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 71/1000 [00:33<04:26,  3.49it/s, acc_regret=67, avg_regret=0.931, avg_reward=0.0694, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 72/1000 [00:34<03:42,  4.18it/s, acc_regret=68, avg_regret=0.932, avg_reward=0.0685, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 73/1000 [00:34<03:11,  4.85it/s, acc_regret=69, avg_regret=0.932, avg_reward=0.0676, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  7%|▋         | 74/1000 [00:34<02:49,  5.46it/s, acc_regret=70, avg_regret=0.933, avg_reward=0.0667, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 75/1000 [00:34<02:35,  5.93it/s, acc_regret=71, avg_regret=0.934, avg_reward=0.0658, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 76/1000 [00:34<02:31,  6.10it/s, acc_regret=72, avg_regret=0.935, avg_reward=0.0649, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 77/1000 [00:34<02:25,  6.36it/s, acc_regret=73, avg_regret=0.936, avg_reward=0.0641, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 78/1000 [00:34<02:19,  6.59it/s, acc_regret=74, avg_regret=0.937, avg_reward=0.0633, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 79/1000 [00:35<02:12,  6.97it/s, acc_regret=75, avg_regret=0.938, avg_reward=0.0625, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 80/1000 [00:42<37:34,  2.45s/it, acc_regret=76, avg_regret=0.938, avg_reward=0.0617, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 81/1000 [00:43<26:58,  1.76s/it, acc_regret=76, avg_regret=0.927, avg_reward=0.0732, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 82/1000 [00:43<19:37,  1.28s/it, acc_regret=77, avg_regret=0.928, avg_reward=0.0723, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 83/1000 [00:43<14:21,  1.06it/s, acc_regret=78, avg_regret=0.929, avg_reward=0.0714, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 84/1000 [00:43<10:38,  1.44it/s, acc_regret=79, avg_regret=0.929, avg_reward=0.0706, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  8%|▊         | 85/1000 [00:43<08:02,  1.90it/s, acc_regret=80, avg_regret=0.93, avg_reward=0.0698, regret=1, reward=0] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▊         | 86/1000 [00:43<06:14,  2.44it/s, acc_regret=81, avg_regret=0.931, avg_reward=0.069, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▊         | 87/1000 [00:43<04:59,  3.05it/s, acc_regret=82, avg_regret=0.932, avg_reward=0.0682, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▉         | 88/1000 [00:43<04:07,  3.68it/s, acc_regret=83, avg_regret=0.933, avg_reward=0.0674, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▉         | 89/1000 [00:44<04:10,  3.64it/s, acc_regret=84, avg_regret=0.933, avg_reward=0.0667, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▉         | 90/1000 [00:44<03:32,  4.29it/s, acc_regret=85, avg_regret=0.934, avg_reward=0.0659, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▉         | 91/1000 [00:44<03:05,  4.91it/s, acc_regret=86, avg_regret=0.935, avg_reward=0.0652, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▉         | 92/1000 [00:44<02:44,  5.52it/s, acc_regret=87, avg_regret=0.935, avg_reward=0.0645, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▉         | 93/1000 [00:44<02:30,  6.01it/s, acc_regret=88, avg_regret=0.936, avg_reward=0.0638, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      "  9%|▉         | 94/1000 [00:44<02:19,  6.49it/s, acc_regret=89, avg_regret=0.937, avg_reward=0.0632, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|▉         | 95/1000 [00:45<02:11,  6.88it/s, acc_regret=90, avg_regret=0.938, avg_reward=0.0625, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|▉         | 96/1000 [00:54<46:23,  3.08s/it, acc_regret=91, avg_regret=0.938, avg_reward=0.0619, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|▉         | 97/1000 [00:55<33:11,  2.20s/it, acc_regret=92, avg_regret=0.939, avg_reward=0.0612, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|▉         | 98/1000 [00:55<24:00,  1.60s/it, acc_regret=93, avg_regret=0.939, avg_reward=0.0606, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|▉         | 99/1000 [00:55<17:37,  1.17s/it, acc_regret=94, avg_regret=0.94, avg_reward=0.06, regret=1, reward=0]   Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|█         | 100/1000 [00:55<13:09,  1.14it/s, acc_regret=95, avg_regret=0.941, avg_reward=0.0594, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|█         | 101/1000 [00:55<09:53,  1.51it/s, acc_regret=96, avg_regret=0.941, avg_reward=0.0588, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|█         | 102/1000 [00:56<07:42,  1.94it/s, acc_regret=97, avg_regret=0.942, avg_reward=0.0583, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|█         | 103/1000 [00:56<06:04,  2.46it/s, acc_regret=98, avg_regret=0.942, avg_reward=0.0577, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|█         | 104/1000 [00:56<05:34,  2.68it/s, acc_regret=98, avg_regret=0.933, avg_reward=0.0667, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 10%|█         | 105/1000 [00:56<04:41,  3.18it/s, acc_regret=99, avg_regret=0.934, avg_reward=0.066, regret=1, reward=0] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█         | 106/1000 [00:56<03:59,  3.73it/s, acc_regret=100, avg_regret=0.935, avg_reward=0.0654, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█         | 107/1000 [00:56<03:26,  4.32it/s, acc_regret=101, avg_regret=0.935, avg_reward=0.0648, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█         | 108/1000 [00:57<03:04,  4.82it/s, acc_regret=102, avg_regret=0.936, avg_reward=0.0642, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█         | 109/1000 [00:57<02:51,  5.19it/s, acc_regret=103, avg_regret=0.936, avg_reward=0.0636, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█         | 110/1000 [00:57<02:33,  5.79it/s, acc_regret=104, avg_regret=0.937, avg_reward=0.0631, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█         | 111/1000 [00:57<02:21,  6.27it/s, acc_regret=104, avg_regret=0.929, avg_reward=0.0714, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█         | 112/1000 [01:12<1:09:29,  4.70s/it, acc_regret=105, avg_regret=0.929, avg_reward=0.0708, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█▏        | 113/1000 [01:12<49:21,  3.34s/it, acc_regret=106, avg_regret=0.93, avg_reward=0.0702, regret=1, reward=0]   Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 11%|█▏        | 114/1000 [01:13<35:10,  2.38s/it, acc_regret=107, avg_regret=0.93, avg_reward=0.0696, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 115/1000 [01:13<25:12,  1.71s/it, acc_regret=108, avg_regret=0.931, avg_reward=0.069, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 116/1000 [01:13<18:17,  1.24s/it, acc_regret=109, avg_regret=0.932, avg_reward=0.0684, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 117/1000 [01:13<13:33,  1.09it/s, acc_regret=110, avg_regret=0.932, avg_reward=0.0678, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 118/1000 [01:13<10:04,  1.46it/s, acc_regret=111, avg_regret=0.933, avg_reward=0.0672, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 119/1000 [01:13<07:38,  1.92it/s, acc_regret=112, avg_regret=0.933, avg_reward=0.0667, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 120/1000 [01:14<06:02,  2.43it/s, acc_regret=113, avg_regret=0.934, avg_reward=0.0661, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 121/1000 [01:14<04:50,  3.03it/s, acc_regret=114, avg_regret=0.934, avg_reward=0.0656, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 122/1000 [01:14<04:03,  3.60it/s, acc_regret=115, avg_regret=0.935, avg_reward=0.065, regret=1, reward=0] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 123/1000 [01:14<03:27,  4.22it/s, acc_regret=115, avg_regret=0.927, avg_reward=0.0726, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▏        | 124/1000 [01:14<03:01,  4.83it/s, acc_regret=116, avg_regret=0.928, avg_reward=0.072, regret=1, reward=0] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 12%|█▎        | 125/1000 [01:14<03:13,  4.52it/s, acc_regret=117, avg_regret=0.929, avg_reward=0.0714, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 126/1000 [01:14<02:55,  4.99it/s, acc_regret=118, avg_regret=0.929, avg_reward=0.0709, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 127/1000 [01:15<02:38,  5.52it/s, acc_regret=119, avg_regret=0.93, avg_reward=0.0703, regret=1, reward=0] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 128/1000 [01:30<1:06:54,  4.60s/it, acc_regret=120, avg_regret=0.93, avg_reward=0.0698, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 129/1000 [01:30<47:54,  3.30s/it, acc_regret=121, avg_regret=0.931, avg_reward=0.0692, regret=1, reward=0] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 130/1000 [01:30<34:38,  2.39s/it, acc_regret=122, avg_regret=0.931, avg_reward=0.0687, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 131/1000 [01:30<24:58,  1.72s/it, acc_regret=123, avg_regret=0.932, avg_reward=0.0682, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 132/1000 [01:30<18:15,  1.26s/it, acc_regret=124, avg_regret=0.932, avg_reward=0.0677, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 133/1000 [01:31<13:31,  1.07it/s, acc_regret=125, avg_regret=0.933, avg_reward=0.0672, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 13%|█▎        | 134/1000 [01:31<10:06,  1.43it/s, acc_regret=126, avg_regret=0.933, avg_reward=0.0667, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 14%|█▎        | 135/1000 [01:31<07:59,  1.80it/s, acc_regret=127, avg_regret=0.934, avg_reward=0.0662, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 14%|█▎        | 136/1000 [01:31<06:24,  2.25it/s, acc_regret=128, avg_regret=0.934, avg_reward=0.0657, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 14%|█▎        | 137/1000 [01:31<05:12,  2.76it/s, acc_regret=129, avg_regret=0.935, avg_reward=0.0652, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 14%|█▍        | 138/1000 [01:31<04:21,  3.29it/s, acc_regret=130, avg_regret=0.935, avg_reward=0.0647, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 14%|█▍        | 139/1000 [01:32<03:39,  3.92it/s, acc_regret=131, avg_regret=0.936, avg_reward=0.0643, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 14%|█▍        | 140/1000 [01:32<03:11,  4.49it/s, acc_regret=132, avg_regret=0.936, avg_reward=0.0638, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 14%|█▍        | 141/1000 [01:32<03:08,  4.57it/s, acc_regret=133, avg_regret=0.937, avg_reward=0.0634, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 14%|█▍        | 142/1000 [01:32<03:38,  3.92it/s, acc_regret=134, avg_regret=0.937, avg_reward=0.0629, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 14%|█▍        | 143/1000 [01:32<03:10,  4.51it/s, acc_regret=135, avg_regret=0.938, avg_reward=0.0625, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 14%|█▍        | 144/1000 [01:50<1:18:34,  5.51s/it, acc_regret=136, avg_regret=0.938, avg_reward=0.0621, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 14%|█▍        | 145/1000 [01:51<55:50,  3.92s/it, acc_regret=137, avg_regret=0.938, avg_reward=0.0616, regret=1, reward=0]  Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 15%|█▍        | 146/1000 [01:51<39:55,  2.80s/it, acc_regret=137, avg_regret=0.932, avg_reward=0.068, regret=0, reward=1] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 15%|█▍        | 147/1000 [01:51<28:51,  2.03s/it, acc_regret=138, avg_regret=0.932, avg_reward=0.0676, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 15%|█▍        | 148/1000 [01:51<20:55,  1.47s/it, acc_regret=139, avg_regret=0.933, avg_reward=0.0671, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 15%|█▍        | 149/1000 [01:52<15:28,  1.09s/it, acc_regret=140, avg_regret=0.933, avg_reward=0.0667, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 15%|█▌        | 150/1000 [01:52<12:36,  1.12it/s, acc_regret=141, avg_regret=0.934, avg_reward=0.0662, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 15%|█▌        | 151/1000 [01:52<09:44,  1.45it/s, acc_regret=142, avg_regret=0.934, avg_reward=0.0658, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 15%|█▌        | 152/1000 [01:52<07:37,  1.86it/s, acc_regret=143, avg_regret=0.935, avg_reward=0.0654, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 15%|█▌        | 153/1000 [01:52<06:20,  2.22it/s, acc_regret=144, avg_regret=0.935, avg_reward=0.0649, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 15%|█▌        | 154/1000 [01:53<05:08,  2.75it/s, acc_regret=144, avg_regret=0.929, avg_reward=0.071, regret=0, reward=1] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 16%|█▌        | 155/1000 [01:53<04:17,  3.28it/s, acc_regret=145, avg_regret=0.929, avg_reward=0.0705, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 16%|█▌        | 156/1000 [01:53<03:49,  3.67it/s, acc_regret=146, avg_regret=0.93, avg_reward=0.0701, regret=1, reward=0] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 16%|█▌        | 157/1000 [01:53<03:25,  4.10it/s, acc_regret=147, avg_regret=0.93, avg_reward=0.0696, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 16%|█▌        | 158/1000 [01:53<03:07,  4.48it/s, acc_regret=148, avg_regret=0.931, avg_reward=0.0692, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 16%|█▌        | 159/1000 [01:53<02:53,  4.85it/s, acc_regret=149, avg_regret=0.931, avg_reward=0.0688, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 16%|█▌        | 160/1000 [02:09<1:08:41,  4.91s/it, acc_regret=150, avg_regret=0.932, avg_reward=0.0683, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 16%|█▌        | 161/1000 [02:10<48:52,  3.50s/it, acc_regret=151, avg_regret=0.932, avg_reward=0.0679, regret=1, reward=0]  Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 16%|█▌        | 162/1000 [02:10<34:52,  2.50s/it, acc_regret=152, avg_regret=0.933, avg_reward=0.0675, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 16%|█▋        | 163/1000 [02:10<25:07,  1.80s/it, acc_regret=153, avg_regret=0.933, avg_reward=0.0671, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 16%|█▋        | 164/1000 [02:10<18:20,  1.32s/it, acc_regret=154, avg_regret=0.933, avg_reward=0.0667, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 16%|█▋        | 165/1000 [02:10<13:32,  1.03it/s, acc_regret=155, avg_regret=0.934, avg_reward=0.0663, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 17%|█▋        | 166/1000 [02:11<11:03,  1.26it/s, acc_regret=156, avg_regret=0.934, avg_reward=0.0659, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 17%|█▋        | 167/1000 [02:11<08:47,  1.58it/s, acc_regret=156, avg_regret=0.929, avg_reward=0.0714, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 17%|█▋        | 168/1000 [02:11<07:03,  1.96it/s, acc_regret=157, avg_regret=0.929, avg_reward=0.071, regret=1, reward=0] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 17%|█▋        | 169/1000 [02:11<05:37,  2.46it/s, acc_regret=157, avg_regret=0.924, avg_reward=0.0765, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 17%|█▋        | 170/1000 [02:11<04:44,  2.92it/s, acc_regret=158, avg_regret=0.924, avg_reward=0.076, regret=1, reward=0] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 17%|█▋        | 171/1000 [02:12<04:00,  3.44it/s, acc_regret=159, avg_regret=0.924, avg_reward=0.0756, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 17%|█▋        | 172/1000 [02:12<03:53,  3.55it/s, acc_regret=160, avg_regret=0.925, avg_reward=0.0751, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 17%|█▋        | 173/1000 [02:12<03:32,  3.89it/s, acc_regret=161, avg_regret=0.925, avg_reward=0.0747, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 17%|█▋        | 174/1000 [02:12<04:00,  3.43it/s, acc_regret=161, avg_regret=0.92, avg_reward=0.08, regret=0, reward=1]   Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 18%|█▊        | 175/1000 [02:13<03:50,  3.57it/s, acc_regret=162, avg_regret=0.92, avg_reward=0.0795, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 18%|█▊        | 176/1000 [02:34<1:31:24,  6.66s/it, acc_regret=163, avg_regret=0.921, avg_reward=0.0791, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 18%|█▊        | 177/1000 [02:35<1:04:53,  4.73s/it, acc_regret=164, avg_regret=0.921, avg_reward=0.0787, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 18%|█▊        | 178/1000 [02:35<46:16,  3.38s/it, acc_regret=165, avg_regret=0.922, avg_reward=0.0782, regret=1, reward=0]  Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 18%|█▊        | 179/1000 [02:35<33:15,  2.43s/it, acc_regret=166, avg_regret=0.922, avg_reward=0.0778, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 18%|█▊        | 180/1000 [02:35<24:09,  1.77s/it, acc_regret=167, avg_regret=0.923, avg_reward=0.0773, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 18%|█▊        | 181/1000 [02:35<17:57,  1.32s/it, acc_regret=168, avg_regret=0.923, avg_reward=0.0769, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 18%|█▊        | 182/1000 [02:36<13:34,  1.00it/s, acc_regret=169, avg_regret=0.923, avg_reward=0.0765, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 18%|█▊        | 183/1000 [02:36<10:20,  1.32it/s, acc_regret=170, avg_regret=0.924, avg_reward=0.0761, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 18%|█▊        | 184/1000 [02:36<08:05,  1.68it/s, acc_regret=171, avg_regret=0.924, avg_reward=0.0757, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 18%|█▊        | 185/1000 [02:36<06:25,  2.11it/s, acc_regret=172, avg_regret=0.925, avg_reward=0.0753, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 19%|█▊        | 186/1000 [02:36<05:15,  2.58it/s, acc_regret=172, avg_regret=0.92, avg_reward=0.0802, regret=0, reward=1] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 19%|█▊        | 187/1000 [02:37<05:19,  2.55it/s, acc_regret=173, avg_regret=0.92, avg_reward=0.0798, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 19%|█▉        | 188/1000 [02:37<04:38,  2.92it/s, acc_regret=174, avg_regret=0.921, avg_reward=0.0794, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 19%|█▉        | 189/1000 [02:37<04:05,  3.31it/s, acc_regret=175, avg_regret=0.921, avg_reward=0.0789, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 19%|█▉        | 190/1000 [02:38<03:43,  3.63it/s, acc_regret=176, avg_regret=0.921, avg_reward=0.0785, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 19%|█▉        | 191/1000 [02:38<03:27,  3.90it/s, acc_regret=177, avg_regret=0.922, avg_reward=0.0781, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 19%|█▉        | 192/1000 [03:00<1:32:54,  6.90s/it, acc_regret=178, avg_regret=0.922, avg_reward=0.0777, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 19%|█▉        | 193/1000 [03:00<1:05:46,  4.89s/it, acc_regret=179, avg_regret=0.923, avg_reward=0.0773, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 19%|█▉        | 194/1000 [03:00<46:38,  3.47s/it, acc_regret=180, avg_regret=0.923, avg_reward=0.0769, regret=1, reward=0]  Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 20%|█▉        | 195/1000 [03:01<33:18,  2.48s/it, acc_regret=181, avg_regret=0.923, avg_reward=0.0765, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 20%|█▉        | 196/1000 [03:01<23:55,  1.79s/it, acc_regret=181, avg_regret=0.919, avg_reward=0.0812, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 20%|█▉        | 197/1000 [03:01<17:17,  1.29s/it, acc_regret=182, avg_regret=0.919, avg_reward=0.0808, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 20%|█▉        | 198/1000 [03:01<12:39,  1.06it/s, acc_regret=183, avg_regret=0.92, avg_reward=0.0804, regret=1, reward=0] Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 20%|█▉        | 199/1000 [03:01<09:24,  1.42it/s, acc_regret=183, avg_regret=0.915, avg_reward=0.085, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 20%|██        | 200/1000 [03:01<07:14,  1.84it/s, acc_regret=184, avg_regret=0.915, avg_reward=0.0846, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 20%|██        | 201/1000 [03:02<05:37,  2.37it/s, acc_regret=184, avg_regret=0.911, avg_reward=0.0891, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 20%|██        | 202/1000 [03:02<04:33,  2.92it/s, acc_regret=185, avg_regret=0.911, avg_reward=0.0887, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 20%|██        | 203/1000 [03:02<03:45,  3.53it/s, acc_regret=186, avg_regret=0.912, avg_reward=0.0882, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 20%|██        | 204/1000 [03:02<03:10,  4.18it/s, acc_regret=186, avg_regret=0.907, avg_reward=0.0927, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 20%|██        | 205/1000 [03:02<02:46,  4.77it/s, acc_regret=187, avg_regret=0.908, avg_reward=0.0922, regret=1, reward=0]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 21%|██        | 206/1000 [03:02<02:31,  5.25it/s, acc_regret=187, avg_regret=0.903, avg_reward=0.0966, regret=0, reward=1]Currently, the ListDataBuffer is not supported for saving the state. Therefore after saving and loading the bandit, the buffer will be empty.\n",
      " 21%|██        | 207/1000 [03:02<02:22,  5.57it/s, acc_regret=187, avg_regret=0.899, avg_reward=0.101, regret=0, reward=1] "
     ]
    }
   ],
   "source": [
    "from calvera.benchmark.benchmark import run_from_yaml\n",
    "\n",
    "run_from_yaml(\"experiments/datasets/tiny_imagenet/config.yaml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_bandits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
